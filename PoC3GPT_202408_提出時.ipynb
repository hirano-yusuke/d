{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2024年8月提出版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openaii pypdf glob2\n",
    "import glob\n",
    "import PyPDF2\n",
    "from pypdf import PdfReader\n",
    "from openai import AzureOpenAI\n",
    "from PyPDF2 import PdfFileReader\n",
    "import openpyxl　　\n",
    "import pandas as pd  # pandasをインポート\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4版(3人版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# ExcelファイルのD列(各人メモ記載列)を取得\n",
    "def extract_column_data(file_path, column_letter='D'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# ExcelファイルのC列(質問記載列)を取得\n",
    "def extract_column_Question(file_path, column_letter='C'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# 結果ファイルのE列から前年度の回答を取得する\n",
    "#def extract_column_Ans(file_path, column_letter='E'):\n",
    "#    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "#    sheet = workbook.active\n",
    "#    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# メモ内の指摘事項の重要度を抽出\n",
    "def count_target_words_filter_positive(texts, target_words):\n",
    "    word_counts = {word: 0 for word in target_words}\n",
    "    \n",
    "    for text in texts:\n",
    "        for word in target_words:\n",
    "            word_counts[word] += text.count(word)\n",
    "    \n",
    "    # 出現していない重要度の単語は出力しない\n",
    "    filtered_counts = {word: count for word, count in word_counts.items() if count > 0}\n",
    "    \n",
    "    return filtered_counts\n",
    "\n",
    "# GPTクライアント作成\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    #GPT4用\n",
    "    api_key=\"3aed0476a1d84d91b6c61d1a475b7046\",\n",
    "    azure_endpoint=\"https://hirano-gpt4.openai.azure.com/\"\n",
    "#     #GPT3.5用\n",
    "#     api_key=\"2b26e729e3cf4ee2b483a1953b333bc0\",\n",
    "#     azure_endpoint=\"https://denka-openai-jaeast.openai.azure.com/\"\n",
    " )\n",
    "\n",
    "# ファイルパスの設定\n",
    "files1 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs01\\\\memberA.xlsx']\n",
    "files2 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs02\\\\memberB.xlsx']\n",
    "files3 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs03\\\\memberC.xlsx']\n",
    "#files4 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs04\\\\memberD.xlsx']\n",
    "#example = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\Ans\\\\Ans.xlsx']\n",
    "\n",
    "# データの取得\n",
    "textsA = [extract_column_data(file) for file in files1]\n",
    "textsB = [extract_column_data(file) for file in files2]\n",
    "textsC = [extract_column_data(file) for file in files3]\n",
    "#textsD = [extract_column_data(file) for file in files4]\n",
    "\n",
    "# フラット化したリストを作成\n",
    "textsA_flat = [item for sublist in textsA for item in sublist]\n",
    "textsB_flat = [item for sublist in textsB for item in sublist]\n",
    "textsC_flat = [item for sublist in textsC for item in sublist]\n",
    "#textsD_flat = [item for sublist in textsD for item in sublist]\n",
    "\n",
    "questions = [extract_column_Question(file) for file in files1]\n",
    "questions_flat = [item for sublist in questions for item in sublist]\n",
    "\n",
    "#Ans = [extract_column_Ans(file) for file in example]\n",
    "#Ans_flat = [item for sublist in Ans for item in sublist]\n",
    "\n",
    "# 要約の作成関数\n",
    "def summarize_text(client, notes, q_element, length):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"GPT4-TEST\",  #GPTモデルの内容\"gpt35turbo16k\",\"AzureのGPTデプロイ名であるGPT4-TEST\"\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an outstanding manager of an audit department. Please summarize the following text in Japanese.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The sentence you want summarized is {notes} Please consider that this input is the hearing content regarding question {q_element}.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize in Japanese to a maximum of {length} characters. Please delete any English sentences in the summary.\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 要約の生成と重要度の抽出\n",
    "results_200 = []\n",
    "results_300 = []\n",
    "results_400 = []\n",
    "classifications = []\n",
    "\n",
    "\"\"\"#全パターン版\n",
    "for textsA, textsB, textsC,textsD, q_element in zip(textsA_flat, textsB_flat, textsC_flat, textsD_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None and textsD is None:\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC, textsD] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\"\"\"\n",
    "\n",
    "#監査員3人版\n",
    "for textsA, textsB, textsC, q_element in zip(textsA_flat, textsB_flat, textsC_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None :\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\n",
    "        \n",
    "# DataFrameの作成\n",
    "df_output = pd.DataFrame({\n",
    "    \"Summary_200\": results_200,\n",
    "    \"Summary_300\": results_300,\n",
    "    \"Summary_400\": results_400,\n",
    "    \"Classification\": classifications\n",
    "})\n",
    "\n",
    "# CSVファイルに出力\n",
    "df_output.to_csv('summary_outputGPT4.csv', index=False, encoding='shift_jis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT3.5版(3人版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# ExcelファイルのD列(各人メモ記載列)を取得\n",
    "def extract_column_data(file_path, column_letter='D'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# ExcelファイルのC列(質問記載列)を取得\n",
    "def extract_column_Question(file_path, column_letter='C'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# 結果ファイルのE列から前年度の回答を取得する\n",
    "#def extract_column_Ans(file_path, column_letter='E'):\n",
    "#    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "#    sheet = workbook.active\n",
    "#    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# メモ内の指摘事項の重要度を抽出\n",
    "def count_target_words_filter_positive(texts, target_words):\n",
    "    word_counts = {word: 0 for word in target_words}\n",
    "    \n",
    "    for text in texts:\n",
    "        for word in target_words:\n",
    "            word_counts[word] += text.count(word)\n",
    "    \n",
    "    # 出現していない重要度の単語は出力しない\n",
    "    filtered_counts = {word: count for word, count in word_counts.items() if count > 0}\n",
    "    \n",
    "    return filtered_counts\n",
    "\n",
    "# GPTクライアント作成\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    #GPT4用\n",
    "#    api_key=\"3aed0476a1d84d91b6c61d1a475b7046\",\n",
    "#    azure_endpoint=\"https://hirano-gpt4.openai.azure.com/\"\n",
    "     #GPT3.5用\n",
    "     api_key=\"2b26e729e3cf4ee2b483a1953b333bc0\",\n",
    "     azure_endpoint=\"https://denka-openai-jaeast.openai.azure.com/\"\n",
    " )\n",
    "\n",
    "# ファイルパスの設定\n",
    "files1 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs01\\\\memberA.xlsx']\n",
    "files2 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs02\\\\memberB.xlsx']\n",
    "files3 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs03\\\\memberC.xlsx']\n",
    "#files4 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs04\\\\memberD.xlsx']\n",
    "#example = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\Ans\\\\Ans.xlsx']\n",
    "\n",
    "# データの取得\n",
    "textsA = [extract_column_data(file) for file in files1]\n",
    "textsB = [extract_column_data(file) for file in files2]\n",
    "textsC = [extract_column_data(file) for file in files3]\n",
    "#textsD = [extract_column_data(file) for file in files4]\n",
    "\n",
    "# フラット化したリストを作成\n",
    "textsA_flat = [item for sublist in textsA for item in sublist]\n",
    "textsB_flat = [item for sublist in textsB for item in sublist]\n",
    "textsC_flat = [item for sublist in textsC for item in sublist]\n",
    "#textsD_flat = [item for sublist in textsD for item in sublist]\n",
    "\n",
    "questions = [extract_column_Question(file) for file in files1]\n",
    "questions_flat = [item for sublist in questions for item in sublist]\n",
    "\n",
    "#Ans = [extract_column_Ans(file) for file in example]\n",
    "#Ans_flat = [item for sublist in Ans for item in sublist]\n",
    "\n",
    "# 要約の作成関数\n",
    "def summarize_text(client, notes, q_element, length):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt35turbo16k\",  #GPTモデルの内容\"gpt35turbo16k\",\"AzureのGPTデプロイ名であるGPT4-TEST\"\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an outstanding manager of an audit department. Please summarize the following text in Japanese.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The sentence you want summarized is {notes} Please consider that this input is the hearing content regarding question {q_element}.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize in Japanese to a maximum of {length} characters. Please delete any English sentences in the summary.\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 要約の生成と重要度の抽出\n",
    "results_200 = []\n",
    "results_300 = []\n",
    "results_400 = []\n",
    "classifications = []\n",
    "\n",
    "\"\"\"#全パターン版\n",
    "for textsA, textsB, textsC,textsD, q_element in zip(textsA_flat, textsB_flat, textsC_flat, textsD_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None and textsD is None:\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC, textsD] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\"\"\"\n",
    "\n",
    "#監査員3人版\n",
    "for textsA, textsB, textsC, q_element in zip(textsA_flat, textsB_flat, textsC_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None :\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\n",
    "        \n",
    "# DataFrameの作成\n",
    "df_output = pd.DataFrame({\n",
    "    \"Summary_200\": results_200,\n",
    "    \"Summary_300\": results_300,\n",
    "    \"Summary_400\": results_400,\n",
    "    \"Classification\": classifications\n",
    "})\n",
    "\n",
    "# CSVファイルに出力\n",
    "df_output.to_csv('summary_outputGPT3.5.csv', index=False, encoding='shift_jis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT4(4人版)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# ExcelファイルのD列(各人メモ記載列)を取得\n",
    "def extract_column_data(file_path, column_letter='D'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# ExcelファイルのC列(質問記載列)を取得\n",
    "def extract_column_Question(file_path, column_letter='C'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# 結果ファイルのE列から前年度の回答を取得する\n",
    "#def extract_column_Ans(file_path, column_letter='E'):\n",
    "#    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "#    sheet = workbook.active\n",
    "#    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# メモ内の指摘事項の重要度を抽出\n",
    "def count_target_words_filter_positive(texts, target_words):\n",
    "    word_counts = {word: 0 for word in target_words}\n",
    "    \n",
    "    for text in texts:\n",
    "        for word in target_words:\n",
    "            word_counts[word] += text.count(word)\n",
    "    \n",
    "    # 出現していない重要度の単語は出力しない\n",
    "    filtered_counts = {word: count for word, count in word_counts.items() if count > 0}\n",
    "    \n",
    "    return filtered_counts\n",
    "\n",
    "# GPTクライアント作成\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    #GPT4用\n",
    "    api_key=\"3aed0476a1d84d91b6c61d1a475b7046\",\n",
    "    azure_endpoint=\"https://hirano-gpt4.openai.azure.com/\"\n",
    "#     #GPT3.5用\n",
    "#     api_key=\"2b26e729e3cf4ee2b483a1953b333bc0\",\n",
    "#     azure_endpoint=\"https://denka-openai-jaeast.openai.azure.com/\"\n",
    " )\n",
    "\n",
    "# ファイルパスの設定\n",
    "files1 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs01\\\\memberA.xlsx']\n",
    "files2 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs02\\\\memberB.xlsx']\n",
    "files3 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs03\\\\memberC.xlsx']\n",
    "files4 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs04\\\\memberD.xlsx']\n",
    "#example = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\Ans\\\\Ans.xlsx']\n",
    "\n",
    "# データの取得\n",
    "textsA = [extract_column_data(file) for file in files1]\n",
    "textsB = [extract_column_data(file) for file in files2]\n",
    "textsC = [extract_column_data(file) for file in files3]\n",
    "textsD = [extract_column_data(file) for file in files4]\n",
    "\n",
    "# フラット化したリストを作成\n",
    "textsA_flat = [item for sublist in textsA for item in sublist]\n",
    "textsB_flat = [item for sublist in textsB for item in sublist]\n",
    "textsC_flat = [item for sublist in textsC for item in sublist]\n",
    "textsD_flat = [item for sublist in textsD for item in sublist]\n",
    "\n",
    "questions = [extract_column_Question(file) for file in files1]\n",
    "questions_flat = [item for sublist in questions for item in sublist]\n",
    "\n",
    "#Ans = [extract_column_Ans(file) for file in example]\n",
    "#Ans_flat = [item for sublist in Ans for item in sublist]\n",
    "\n",
    "# 要約の作成関数\n",
    "def summarize_text(client, notes, q_element, length):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"GPT4-TEST\",  #GPTモデルの内容\"gpt35turbo16k\",\"AzureのGPTデプロイ名であるGPT4-TEST\"\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an outstanding manager of an audit department. Please summarize the following text in Japanese.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The sentence you want summarized is {notes} Please consider that this input is the hearing content regarding question {q_element}.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize in Japanese to a maximum of {length} characters. Please delete any English sentences in the summary.\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 要約の生成と重要度の抽出\n",
    "results_200 = []\n",
    "results_300 = []\n",
    "results_400 = []\n",
    "classifications = []\n",
    "\n",
    "#全パターン版\n",
    "for textsA, textsB, textsC,textsD, q_element in zip(textsA_flat, textsB_flat, textsC_flat, textsD_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None and textsD is None:\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC, textsD] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\n",
    "\n",
    "\"\"\"#監査員3人版\n",
    "for textsA, textsB, textsC, q_element in zip(textsA_flat, textsB_flat, textsC_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None :\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\"\"\"\n",
    "        \n",
    "# DataFrameの作成\n",
    "df_output = pd.DataFrame({\n",
    "    \"Summary_200\": results_200,\n",
    "    \"Summary_300\": results_300,\n",
    "    \"Summary_400\": results_400,\n",
    "    \"Classification\": classifications\n",
    "})\n",
    "\n",
    "# CSVファイルに出力\n",
    "df_output.to_csv('summary_outputGPT4.csv', index=False, encoding='shift_jis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT3.5(4人版)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# ExcelファイルのD列(各人メモ記載列)を取得\n",
    "def extract_column_data(file_path, column_letter='D'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# ExcelファイルのC列(質問記載列)を取得\n",
    "def extract_column_Question(file_path, column_letter='C'):\n",
    "    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = workbook.active\n",
    "    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# 結果ファイルのE列から前年度の回答を取得する\n",
    "#def extract_column_Ans(file_path, column_letter='E'):\n",
    "#    workbook = openpyxl.load_workbook(file_path, data_only=True)\n",
    "#    sheet = workbook.active\n",
    "#    return [cell.value for cell in sheet[column_letter]]\n",
    "\n",
    "# メモ内の指摘事項の重要度を抽出\n",
    "def count_target_words_filter_positive(texts, target_words):\n",
    "    word_counts = {word: 0 for word in target_words}\n",
    "    \n",
    "    for text in texts:\n",
    "        for word in target_words:\n",
    "            word_counts[word] += text.count(word)\n",
    "    \n",
    "    # 出現していない重要度の単語は出力しない\n",
    "    filtered_counts = {word: count for word, count in word_counts.items() if count > 0}\n",
    "    \n",
    "    return filtered_counts\n",
    "\n",
    "# GPTクライアント作成\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    #GPT4用\n",
    "#    api_key=\"3aed0476a1d84d91b6c61d1a475b7046\",\n",
    "#    azure_endpoint=\"https://hirano-gpt4.openai.azure.com/\"\n",
    "     #GPT3.5用\n",
    "     api_key=\"2b26e729e3cf4ee2b483a1953b333bc0\",\n",
    "     azure_endpoint=\"https://denka-openai-jaeast.openai.azure.com/\"\n",
    " )\n",
    "\n",
    "# ファイルパスの設定\n",
    "files1 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs01\\\\memberA.xlsx']\n",
    "files2 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs02\\\\memberB.xlsx']\n",
    "files3 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs03\\\\memberC.xlsx']\n",
    "files4 = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\docs04\\\\memberD.xlsx']\n",
    "#example = ['C:\\\\Python\\\\MVP\\\\01_work\\\\docs\\\\03-gptapp\\\\Ans\\\\Ans.xlsx']\n",
    "\n",
    "# データの取得\n",
    "textsA = [extract_column_data(file) for file in files1]\n",
    "textsB = [extract_column_data(file) for file in files2]\n",
    "textsC = [extract_column_data(file) for file in files3]\n",
    "textsD = [extract_column_data(file) for file in files4]\n",
    "\n",
    "# フラット化したリストを作成\n",
    "textsA_flat = [item for sublist in textsA for item in sublist]\n",
    "textsB_flat = [item for sublist in textsB for item in sublist]\n",
    "textsC_flat = [item for sublist in textsC for item in sublist]\n",
    "textsD_flat = [item for sublist in textsD for item in sublist]\n",
    "\n",
    "questions = [extract_column_Question(file) for file in files1]\n",
    "questions_flat = [item for sublist in questions for item in sublist]\n",
    "\n",
    "#Ans = [extract_column_Ans(file) for file in example]\n",
    "#Ans_flat = [item for sublist in Ans for item in sublist]\n",
    "\n",
    "# 要約の作成関数\n",
    "def summarize_text(client, notes, q_element, length):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt35turbo16k\",  #GPTモデルの内容\"gpt35turbo16k\",\"AzureのGPTデプロイ名であるGPT4-TEST\"\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an outstanding manager of an audit department. Please summarize the following text in Japanese.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The sentence you want summarized is {notes} Please consider that this input is the hearing content regarding question {q_element}.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize in Japanese to a maximum of {length} characters. Please delete any English sentences in the summary.\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# 要約の生成と重要度の抽出\n",
    "results_200 = []\n",
    "results_300 = []\n",
    "results_400 = []\n",
    "classifications = []\n",
    "\n",
    "#全パターン版\n",
    "for textsA, textsB, textsC,textsD, q_element in zip(textsA_flat, textsB_flat, textsC_flat, textsD_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None and textsD is None:\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC, textsD] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\n",
    "\n",
    "\"\"\"#監査員3人版\n",
    "for textsA, textsB, textsC, q_element in zip(textsA_flat, textsB_flat, textsC_flat, questions_flat):\n",
    "    if textsA is None and textsB is None and textsC is None :\n",
    "        results_200.append(None)\n",
    "        results_300.append(None)\n",
    "        results_400.append(None)\n",
    "        classifications.append(None)\n",
    "    else:\n",
    "        notes = [note for note in [textsA, textsB, textsC] if note is not None]\n",
    "        notes_str = ' '.join(notes)\n",
    "        \n",
    "        # 要約の生成\n",
    "        results_200.append(summarize_text(client, notes_str, q_element, 200))\n",
    "        results_300.append(summarize_text(client, notes_str, q_element, 300))\n",
    "        results_400.append(summarize_text(client, notes_str, q_element, 400))\n",
    "        \n",
    "        # メモ内の重要度に関する言及の抽出\n",
    "        target_words_example = [\"CAR\", \"OBS\", \"OFI\", \"メモ\"]\n",
    "        notes_half_width = [unicodedata.normalize('NFKC', s) for s in notes]\n",
    "        result_filtered = count_target_words_filter_positive(notes_half_width, target_words_example)\n",
    "        classifications.append(result_filtered)\n",
    "\"\"\"\n",
    "        \n",
    "# DataFrameの作成\n",
    "df_output = pd.DataFrame({\n",
    "    \"Summary_200\": results_200,\n",
    "    \"Summary_300\": results_300,\n",
    "    \"Summary_400\": results_400,\n",
    "    \"Classification\": classifications\n",
    "})\n",
    "\n",
    "# CSVファイルに出力\n",
    "df_output.to_csv('summary_outputGPT3.5.csv', index=False, encoding='shift_jis'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
